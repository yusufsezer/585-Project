{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "type_inference_hmm.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ1HEc79pfRs",
        "colab_type": "code",
        "outputId": "1f58472f-0f4e-499b-ba6f-4532d9655909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Install all required packages\n",
        "!pip install hmmlearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hmmlearn in /usr/local/lib/python3.6/dist-packages (0.2.3)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (0.21.3)\n",
            "Requirement already satisfied: scipy>=0.15 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.17.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUJASLLGEzin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All imports\n",
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from hmmlearn import hmm\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAjRB5k3Q8tT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74bbf1db-e196-4d14-84c1-d1a073640b75"
      },
      "source": [
        "# Connect to Google Drive. We retrieve our data from Google Drive.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqoSfsdaRpqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1b1d0317-87eb-4955-f51a-bc2b01b40617"
      },
      "source": [
        "# Load the data.\n",
        "# NOTE: Data must be uploaded to your Google Drive to be used;\n",
        "# It should be available on the GitHub repo.\n",
        "raw_data = pd.read_csv(\"drive/My Drive/types_dataset_utf8.csv\")\n",
        "raw_data = raw_data.fillna(method=\"ffill\")\n",
        "print(raw_data.tail(5))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               Sentence #    Word  POS Tag\n",
            "12190865  Sentence: 13342     's'  NaN   O\n",
            "12190866  Sentence: 13342       ;  NaN   O\n",
            "12190867  Sentence: 13342  import  NaN   O\n",
            "12190868  Sentence: 13342     's'  NaN   O\n",
            "12190869  Sentence: 13342       ;  NaN   O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjWyVOd1qzgJ",
        "colab_type": "code",
        "outputId": "6388b62f-7673-4dfc-b987-85eabcad9111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "token_vocab = set()\n",
        "tag_vocab = set()\n",
        "\n",
        "def parse_data(data):\n",
        "    \"\"\"\n",
        "    Parses table into an pandas series (1D array) of\n",
        "    (list-of-words, list-of-tags) pairs.\n",
        "    \"\"\"\n",
        "    construct_word_tag_pair = lambda df: (df['Word'].values.tolist(), df['Tag'].values.tolist())\n",
        "    return data.groupby('Sentence #').apply(construct_word_tag_pair)\n",
        "\n",
        "sentence_data = parse_data(raw_data)\n",
        "sentence_data = sentence_data.sample(frac=1) # shuffle the dataset\n",
        "\n",
        "test_portion = int(len(sentence_data) * 0.05)\n",
        "\n",
        "# train on first 95% of the dataset\n",
        "train_data = sentence_data[:-test_portion]\n",
        "\n",
        "# test on last 5% of dataset\n",
        "test_data = sentence_data[-test_portion:]\n",
        "\n",
        "# temporarily count all tags in order to filter out the rare ones\n",
        "tmp_tag_counts = Counter()\n",
        "\n",
        "# collect all tokens and tags\n",
        "for tokens, tags in tqdm(train_data):\n",
        "    assert(len(tokens) == len(tags))\n",
        "    token_vocab |= set(tokens)\n",
        "    tag_vocab |= set(tags)\n",
        "    tmp_tag_counts.update(tags)\n",
        "\n",
        "# restrict number of tags in order to make things compute faster\n",
        "MAX_TAGS = 100\n",
        "tag_vocab = set([tag for tag, count in tmp_tag_counts.most_common(MAX_TAGS)])\n",
        "tag_vocab.add('<unk>') # necessary to cutting down on number of tags in model\n",
        "token_vocab.add('<unk>') # necessary for inferring new unseen tokens\n",
        "\n",
        "token_vocab = list(sorted(token_vocab))\n",
        "tag_vocab = list(sorted(tag_vocab))\n",
        "print(tag_vocab)\n",
        "\n",
        "token_map = {token: i for i, token in enumerate(token_vocab)}\n",
        "tag_map = {tag: i for i, tag in enumerate(tag_vocab)}\n",
        "\n",
        "num_tokens = len(token_vocab)\n",
        "num_tags = len(tag_vocab)\n",
        "\n",
        "# Definition of matrices:\n",
        "# start_tags[i] = prob(sentence starts with tag i)\n",
        "# transitions[j][i] = prob(tag i given tag j was previous)\n",
        "# emissions[j][i] = prob(token i given tag j)\n",
        "\n",
        "start_tags = np.zeros((num_tags,))\n",
        "transitions = np.zeros((num_tags, num_tags))\n",
        "emissions = np.zeros((num_tags, num_tokens))\n",
        "\n",
        "for tokens, tags in tqdm(train_data):\n",
        "    tags = [tag if tag in tag_vocab else '<unk>'\n",
        "            for tag in tags]\n",
        "    start_tags[tag_map[tags[0]]] += 1\n",
        "    for i in range(len(tags) - 1):\n",
        "        transitions[tag_map[tags[i]]][tag_map[tags[i + 1]]] += 1\n",
        "        emissions[tag_map[tags[i]]][token_map[tokens[i]]] += 1\n",
        "    emissions[tag_map[tags[len(tags) - 1]]][token_map[tokens[len(tags) - 1]]] += 1\n",
        "\n",
        "print('token vocab length:', len(token_vocab))\n",
        "print('tag vocab length:', len(tag_vocab))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12676/12676 [00:01<00:00, 10132.31it/s]\n",
            "  0%|          | 59/12676 [00:00<00:24, 511.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['$ArrayConstructor$', '$Assertion$', '$BigNumber$', '$ComponentFixture$', '$Config$', '$Console$', '$ContentServicesPage$', '$DartDebugClient$', '$Date$', '$DateConstructor$', '$Document$', '$EditorState<any>$', '$Element$', '$Equal$', '$Error$', '$ErrorConstructor$', '$Event$', '$ExchangeContract$', '$ExpectStatic$', '$FileModel$', '$FormFieldModel$', '$Function$', '$FunctionConstructor$', '$GomlNode$', '$HTMLDivElement$', '$HTMLElement$', '$HTMLInputElement$', '$IArguments$', '$IFilteringOperation$', '$IPosition$', '$IServiceContainer$', '$IServiceManager$', '$IWorkspaceService$', '$IgxColumnComponent$', '$IgxGridCellComponent$', '$IgxGridComponent$', '$IgxHierarchicalGridComponent$', '$IgxTreeGridComponent$', '$JSON$', '$KeyboardEvent$', '$Location$', '$Math$', '$Object$', '$ObjectConstructor$', '$Partial$', '$Position$', '$Promise$', '$Promise<T>$', '$Promise<any>$', '$Promise<any[]>$', '$Promise<boolean>$', '$Promise<string>$', '$Promise<unknown>$', '$Promise<void>$', '$PromiseConstructor$', '$PropertyDescriptor$', '$PythonInterpreter$', '$QUnitStatic$', '$RegExp$', '$RegExpConstructor$', '$RegExpExecArray$', '$ServerInfo$', '$ServerInfo[]$', '$SinonSpy$', '$SinonStub$', '$Storage$', '$StringConstructor$', '$SymbolConstructor$', '$T$', '$T[]$', '$TasksCloudDemoPage$', '$TasksPage$', '$TestFile$', '$TestFunction$', '$TestSuite$', '$Tests$', '$TypeErrorConstructor$', '$U[]$', '$XMLHttpRequest$', '$any$', '$any[]$', '$boolean$', '$complex$', '$e$', '$false$', '$never$', '$null$', '$number$', '$number[]$', '$object$', '$string$', '$string[]$', '$t$', '$true$', '$undefined$', '$undefined[]$', '$void$', '$void)[]$', '${}$', '<unk>', 'O']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12676/12676 [00:33<00:00, 373.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "token vocab length: 94314\n",
            "tag vocab length: 101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLjZchfo93_6",
        "colab_type": "code",
        "outputId": "fd57ff87-ff57-4412-adb4-9699a46ddec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# general constant to prevent zeros for P(prev_tag|tag) or P(token|tag)\n",
        "SMOOTHING_CONSTANT = 0.01\n",
        "\n",
        "# add-k smoothing\n",
        "print('Performing add-k smoothing...')\n",
        "start_tags += SMOOTHING_CONSTANT\n",
        "transitions += SMOOTHING_CONSTANT\n",
        "emissions += SMOOTHING_CONSTANT\n",
        "\n",
        "# constant to fix class imbalance\n",
        "SCALE_HYPERPARAM = 0.1\n",
        "\n",
        "# reduce probabilities of transitioning to 'O'\n",
        "o_idx = tag_map['O']\n",
        "print('Scaling O tag probabilities to reduce class imbalance...')\n",
        "start_tags[o_idx] *= SCALE_HYPERPARAM\n",
        "transitions[:, o_idx] *= SCALE_HYPERPARAM\n",
        "\n",
        "# normalize HMM probability tables\n",
        "print('Normalizing start tag probabilities...')\n",
        "start_tags = start_tags / np.linalg.norm(start_tags, ord=1)\n",
        "\n",
        "print('Normalizing previous tag probabilities...')\n",
        "for i in tqdm(range(num_tags)):\n",
        "    transitions[i, :] /= np.linalg.norm(transitions[i], ord=1)\n",
        "\n",
        "print('Normalizing tag emission probabilities...')\n",
        "for i in tqdm(range(num_tags)):\n",
        "    emissions[i, :] /= np.linalg.norm(emissions[i], ord=1)\n",
        "\n",
        "assert(abs(sum(start_tags) - 1) < 0.01)\n",
        "assert(all([abs(sum(row) - 1) < 0.01 for row in transitions]))\n",
        "assert(all([abs(sum(row) - 1) < 0.01 for row in emissions]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 101/101 [00:00<00:00, 63246.45it/s]\n",
            "100%|██████████| 101/101 [00:00<00:00, 3025.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Performing add-k smoothing...\n",
            "Scaling O tag probabilities to reduce class imbalance...\n",
            "Normalizing start tag probabilities...\n",
            "Normalizing previous tag probabilities...\n",
            "Normalizing tag emission probabilities...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqSdSBPWp5i-",
        "colab_type": "code",
        "outputId": "4da90418-8a45-4275-aeb8-1a5649077d68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model = hmm.MultinomialHMM(n_components=len(tag_vocab))\n",
        "model.startprob_ = start_tags\n",
        "model.transmat_ = transitions\n",
        "model.emissionprob_ = emissions\n",
        "\n",
        "unk_index = token_vocab.index('<unk>')\n",
        "total_items_to_predict = 0.001  # prevent div by 0 if there is no test data\n",
        "correctly_predicted = 0\n",
        "o_idx = tag_vocab.index('O')\n",
        "for i, data in tqdm(enumerate(test_data)):\n",
        "    tokens, tags = data\n",
        "    token_indices = [token_vocab.index(token) if token in token_vocab else unk_index for token in tokens]\n",
        "    model_input = np.array([token_indices]).T\n",
        "    pred_indices = model.predict(model_input, )\n",
        "    pred_tags = [tag_vocab[pred_indices[i]] for i in range(len(pred_indices))]\n",
        "    total_items_to_predict += sum([tag != 'O' for tag in tags])\n",
        "    correctly_predicted += sum([real_tag == pred_tag for real_tag, pred_tag in zip(tags, pred_tags) if real_tag != 'O'])\n",
        "    if i % 100 == 0:\n",
        "        print(i, 'current accuracy:', correctly_predicted / total_items_to_predict)\n",
        "\n",
        "print('final accuracy', correctly_predicted / total_items_to_predict)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  3.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 current accuracy: 0.33329630041106545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "101it [03:47,  1.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100 current accuracy: 0.6354669106990555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "201it [13:31,  1.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "200 current accuracy: 0.7612161006022585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "301it [15:28,  3.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "300 current accuracy: 0.7482386859890838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "401it [19:57,  2.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "400 current accuracy: 0.7478168611033773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "501it [21:38,  2.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "500 current accuracy: 0.7406736127728282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "601it [26:15,  1.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "600 current accuracy: 0.735260758267766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "667it [27:34,  1.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "final accuracy 0.7312153416187809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}